{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Machine Learning Capstone Project\n",
    "\n",
    "## State Farm Distracted Driver Detection (Can computer vision spot distracted drivers?)\n",
    "\n",
    "---\n",
    "### The Road Ahead\n",
    "\n",
    "We break the notebook into separate steps.  Feel free to use the links below to navigate the notebook.\n",
    "\n",
    "* [Step 0](#step0): Import Datasets\n",
    "* [Step 1](#step1): Data Analysis and Preprocessing\n",
    "* [Step 2](#step2): Create a CNN to classify driver images (from scratch)\n",
    "* [Step 3](#step3): Use a CNN to classify driver images (using transfer learning)\n",
    "* [Step 4](#step4): Create a CNN to classify driver images (using transfer learning)\n",
    "* [Step 5](#step5): Algorithm test result\n",
    "\n",
    "---\n",
    "<a id='step0'></a>\n",
    "## Step 0: Import Datasets\n",
    "\n",
    "### Import Driver Image Dataset\n",
    "\n",
    "In the code cell below, we import a dataset of driver images. We populate a few variables through the use of the `load_files` function from the scikit-learn library:\n",
    "- `train_files`, `valid_files`, `test_files` - numpy arrays containing file paths to images\n",
    "- `train_targets`, `valid_targets`, `test_targets` - numpy arrays containing onehot-encoded classification labels \n",
    "- `label_names` - list of string-valued label codes of driver behaviors for translating labels :\n",
    "\n",
    "    * c0: normal driving\n",
    "    * c1: texting - right\n",
    "    * c2: talking on the phone - right\n",
    "    * c3: texting - left\n",
    "    * c4: talking on the phone - left\n",
    "    * c5: operating the radio\n",
    "    * c6: drinking\n",
    "    * c7: reaching behind\n",
    "    * c8: hair and makeup\n",
    "    * c9: talking to passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 102150 total driver images provided by State Farm:\n",
      "22424 train driver images\n",
      "79726 test driver images\n",
      "\n",
      "There are 10 total driver behavior categories.\n",
      "\n",
      "To avoid running out of memory,\n",
      "we select 448 images from original train set\n",
      "and ignore the remaining 21976 images.\n",
      "\n",
      "Among the 448 randomly selected images,\n",
      "we use 358 images for training and\n",
      "we use 90 images for validation.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# define function to load train and test image datasets provided by State Farm\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    driver_files = np.array(data['filenames'])\n",
    "    driver_targets = np_utils.to_categorical(np.array(data['target']), 10)\n",
    "    return driver_files, driver_targets\n",
    "\n",
    "# load original train and test datasets provided by State Farm\n",
    "train_files, train_targets = load_dataset('imgs/train')\n",
    "test_files, test_targets = load_dataset('imgs/test')\n",
    "\n",
    "print('There are %s total driver images provided by State Farm:' % len(np.hstack([train_files, test_files])))\n",
    "print('%d train driver images' % len(train_files))\n",
    "print('%d test driver images\\n' % len(test_files))\n",
    "\n",
    "# load list of label codes of driver behaviors\n",
    "label_names = [item[11:13] for item in sorted(glob(\"imgs/train/*/\"))]\n",
    "\n",
    "print('There are %d total driver behavior categories.\\n' % len(label_names))\n",
    "\n",
    "# Since the number of driver images in original train data set provided by State Farm is too large, for avoidance of \n",
    "# running out of computer memory when we transform them into tensors to feed and train the CNN models, \n",
    "# we randomly sample a particular ratio (0.5) of them to use, and ignore the remaining portion (ratio 0.5).\n",
    "use_files, non_use_files, use_targets, non_use_targets = \\\n",
    "            train_test_split(train_files, train_targets, test_size=0.5, random_state=5)\n",
    "\n",
    "print('To avoid running out of memory,')\n",
    "print('we select %s images from original train set' % len(use_files))\n",
    "print('and ignore the remaining %s images.\\n' % len(non_use_files))\n",
    "\n",
    "# shuffle and split the sampled \"use\" dataset into training set and validation set\n",
    "train_files, valid_files, train_targets, valid_targets = \\\n",
    "            train_test_split(use_files, use_targets, test_size=0.2, random_state=5)\n",
    "\n",
    "print('Among the %s randomly selected images,' % len(use_files))\n",
    "print('we use %d images for training and' % len(train_files))\n",
    "print('we use %d images for validation.' % len(valid_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_image_filename_list = [test_file_path[15:] for test_file_path in test_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step1'></a>\n",
    "## Step 1: Data Analysis and Preprocessing\n",
    "\n",
    "### Data Analysis\n",
    "\n",
    "In the code cells below, we read the **driver_imgs_list.csv** file provided by State Farm. This csv file is a list of original training images, their subject (driver id), and classname (label id). We then analyze this original train data set. There is just a little bit size imbalance between different classes. Note that class 'c0' has the maximum number of 2489 images and class 'c8' has the minimum number of 1911 images among all the 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject classname            img\n",
       "0    p002        c0  img_44733.jpg\n",
       "1    p002        c0  img_72999.jpg\n",
       "2    p002        c0  img_25094.jpg\n",
       "3    p002        c0  img_69092.jpg\n",
       "4    p002        c0  img_92629.jpg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "training_images_df = pd.read_csv(\"driver_imgs_list.csv\")\n",
    "display(training_images_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22424</td>\n",
       "      <td>22424</td>\n",
       "      <td>22424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>22424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>p021</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_91430.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1237</td>\n",
       "      <td>2489</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject classname            img\n",
       "count    22424     22424          22424\n",
       "unique      26        10          22424\n",
       "top       p021        c0  img_91430.jpg\n",
       "freq      1237      2489              1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(training_images_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c0    2489\n",
      "c3    2346\n",
      "c4    2326\n",
      "c6    2325\n",
      "c2    2317\n",
      "c5    2312\n",
      "c1    2267\n",
      "c9    2129\n",
      "c7    2002\n",
      "c8    1911\n",
      "Name: classname, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(training_images_df['classname'].value_counts(sort=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "When using TensorFlow as backend, Keras CNNs require a 4D array (which we'll also refer to as a 4D tensor) as input, with shape\n",
    "\n",
    "$$\n",
    "(\\text{nb_samples}, \\text{rows}, \\text{columns}, \\text{channels}),\n",
    "$$\n",
    "\n",
    "where `nb_samples` corresponds to the total number of images (or samples), and `rows`, `columns`, and `channels` correspond to the number of rows, columns, and channels for each image, respectively.  \n",
    "\n",
    "The `path_to_tensor` function below takes a string-valued file path to a color image as input and returns a 4D tensor suitable for supplying to a Keras CNN.  The function first loads the image and resizes it to a square image that is $224 \\times 224$ pixels.  Next, the image is converted to an array, which is then resized to a 4D tensor.  In this case, since we are working with color images, each image has three channels.  Likewise, since we are processing a single image (or sample), the returned tensor will always have shape\n",
    "\n",
    "$$\n",
    "(1, 224, 224, 3).\n",
    "$$\n",
    "\n",
    "The `paths_to_tensor` function takes a numpy array of string-valued image paths as input and returns a 4D tensor with shape \n",
    "\n",
    "$$\n",
    "(\\text{nb_samples}, 224, 224, 3).\n",
    "$$\n",
    "\n",
    "Here, `nb_samples` is the number of samples, or number of images, in the supplied array of image paths.  It is best to think of `nb_samples` as the number of 3D tensors (where each 3D tensor corresponds to a different image) in your dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, we rescale the images by dividing every pixel in every image by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 358/358 [00:02<00:00, 155.74it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 138.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "\n",
    "#run out of memory\n",
    "#test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step2'></a>\n",
    "## Step 2: Create a CNN to classify driver images (from scratch)\n",
    "\n",
    "We will use Keras and Tensorflow to implement our CNN model. In this step, we will\n",
    "provide the first architecture of the CNN model we design. And then test the performance\n",
    "result of the first CNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "\n",
    "We create a CNN to classify driver behaviors. At the end of code cell block, we summarize the layers of the CNN model by executing the line:\n",
    "    \n",
    "        model.summary()\n",
    "\n",
    "We use three convolotion layers followed by three max pooling layers interleavingly and then use two fully connected layers behind in the CNN architecture. We also adopt batch_normalization layer between each convolution layer or dense layer and their activation layer to avoid covariate shift and accelerate the training process. The number of filters in each convolution layer is twice to the previous one (this is a common practice), and we choose 16, 32, and 64 filters to extract the feature maps (regional information). The window size of feature filter in each convolution layer and also the pool size in each max pooling layer are both (2,2), and it's also a kind of typical choices. We set the padding parameter to be 'same' for not loss information near matrix boundaries. The activation function in each layer beside output is ReLU for dealing with the vanishing gradient problem, and that in output layer is SoftMax for calculation of probabilities on the multi-classes. In max pooling layers, we set the strides parameter to be 2 for half both length and width of each 2D feature map (dimension reduction), and such strides setting is typical. Before fully connected layers, we use the GlobalAveragePooling2D layer, which can immediately reduce the amount of parameters and avoid overfitting as well as save much time. We adopt the dropout layers with probability 0.2 to reduce opportunity of overfitting. We choose the number of nodes to be 64 in the first fully connected layer for initial try, and due to the 10 classes of driver behaviors, the number of nodes in output layer is 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 224, 224, 16)      208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 112, 112, 16)      64        \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 112, 112, 32)      2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 56, 56, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 56, 56, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_14  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 16,098\n",
      "Trainable params: 15,726\n",
      "Non-trainable params: 372\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=2, padding='same', input_shape=(224, 224, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "We train the first CNN model we design in the code cell below. Use model checkpointing to save the model that attains the best validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358 samples, validate on 90 samples\n",
      "Epoch 1/10\n",
      "340/358 [===========================>..] - ETA: 2s - loss: 2.3103 - acc: 0.1206Epoch 00000: val_loss improved from inf to 2.28470, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "358/358 [==============================] - 50s - loss: 2.3093 - acc: 0.1201 - val_loss: 2.2847 - val_acc: 0.1889\n",
      "Epoch 2/10\n",
      "340/358 [===========================>..] - ETA: 2s - loss: 2.2734 - acc: 0.1559Epoch 00001: val_loss improved from 2.28470 to 2.28292, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "358/358 [==============================] - 49s - loss: 2.2744 - acc: 0.1564 - val_loss: 2.2829 - val_acc: 0.1889\n",
      "Epoch 3/10\n",
      "340/358 [===========================>..] - ETA: 2s - loss: 2.2519 - acc: 0.1647Epoch 00002: val_loss did not improve\n",
      "358/358 [==============================] - 48s - loss: 2.2468 - acc: 0.1704 - val_loss: 2.2988 - val_acc: 0.1889\n",
      "Epoch 4/10\n",
      "340/358 [===========================>..] - ETA: 2s - loss: 2.2317 - acc: 0.1824Epoch 00003: val_loss did not improve\n",
      "358/358 [==============================] - 47s - loss: 2.2314 - acc: 0.1816 - val_loss: 2.3353 - val_acc: 0.1889\n",
      "Epoch 5/10\n",
      "340/358 [===========================>..] - ETA: 2s - loss: 2.2279 - acc: 0.1676Epoch 00004: val_loss did not improve\n",
      "358/358 [==============================] - 49s - loss: 2.2240 - acc: 0.1760 - val_loss: 2.3946 - val_acc: 0.1889\n",
      "Epoch 6/10\n",
      "340/358 [===========================>..] - ETA: 2s - loss: 2.1973 - acc: 0.2206Epoch 00005: val_loss did not improve\n",
      "358/358 [==============================] - 49s - loss: 2.1959 - acc: 0.2207 - val_loss: 2.5228 - val_acc: 0.1889\n",
      "Epoch 7/10\n",
      "340/358 [===========================>..] - ETA: 2s - loss: 2.1882 - acc: 0.2118Epoch 00006: val_loss did not improve\n",
      "358/358 [==============================] - 47s - loss: 2.1885 - acc: 0.2123 - val_loss: 2.5767 - val_acc: 0.1889\n",
      "Epoch 8/10\n",
      "340/358 [===========================>..] - ETA: 2s - loss: 2.1674 - acc: 0.2206Epoch 00007: val_loss did not improve\n",
      "358/358 [==============================] - 47s - loss: 2.1700 - acc: 0.2179 - val_loss: 2.6312 - val_acc: 0.1889\n",
      "Epoch 9/10\n",
      "340/358 [===========================>..] - ETA: 2s - loss: 2.1833 - acc: 0.2059Epoch 00008: val_loss did not improve\n",
      "358/358 [==============================] - 50s - loss: 2.1824 - acc: 0.2039 - val_loss: 2.7068 - val_acc: 0.1889\n",
      "Epoch 10/10\n",
      "340/358 [===========================>..] - ETA: 2s - loss: 2.1666 - acc: 0.2353Epoch 00009: val_loss did not improve\n",
      "358/358 [==============================] - 49s - loss: 2.1640 - acc: 0.2374 - val_loss: 3.0050 - val_acc: 0.1889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2665c63bac8>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(train_tensors, train_targets, \n",
    "          validation_data=(valid_tensors, valid_targets),\n",
    "          epochs=20, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model with the Best Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.from_scratch.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "\n",
    "In the code cell below, we test our first CNN model on the testing data set of driver images. The prediction probability results of all the test images are written into the csv file: **CNN_1_test_probability.csv**, following the submission format defined by Kaggle.\n",
    "\n",
    "**The score (evaluation metrics: logarithmic loss function) of our first CNN model is 2.86036.**\n",
    "\n",
    "**The test result of our first CNN model is ranked 1367 out of 1440 in public leader board.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [00:05<00:00, 15.71it/s]\n"
     ]
    }
   ],
   "source": [
    "driver_behavior_predictions = []\n",
    "for test_file in tqdm(test_files):\n",
    "    test_tensor = path_to_tensor(test_file)\n",
    "    test_tensor = np.vstack(test_tensor).astype('float32')/255\n",
    "    driver_behavior_predictions.append(model.predict(np.expand_dims(test_tensor, axis=0))[0])\n",
    "\n",
    "#driver_behavior_predictions = [model.predict(np.expand_dims(test_tensor, axis=0))[0] for test_tensor in test_tensors]\n",
    "\n",
    "test_image_probability_csv = np.column_stack((np.asarray(test_image_filename_list), \\\n",
    "                                              np.asarray(driver_behavior_predictions, dtype=np.float32)))\n",
    "\n",
    "np.savetxt('submission/CNN_1_test_probability.csv', test_image_probability_csv, delimiter=',', \\\n",
    "           comments='', newline='\\n', fmt='%s', header='img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9')\n",
    "\n",
    "# get index of predicted dog breed for each image in test set\n",
    "#dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "#test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_targets, axis=1))/len(dog_breed_predictions)\n",
    "#print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step3'></a>\n",
    "## Step 3: Use a CNN to classify driver images (using transfer learning)\n",
    "\n",
    "To reduce training time without sacrificing accuracy, we will train a CNN model using\n",
    "transfer learning. In this step, our CNN model will use the pre-trained VGG-16 model as a\n",
    "fixed feature extractor, where the last convolutional output of VGG-16 is fed as input to our\n",
    "model.\n",
    "\n",
    "## VGG16\n",
    "### Obtain Bottleneck Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "# https://keras.io/applications/#vgg16\n",
    "# NOT include the 3 fully-connected layers at the top of the network\n",
    "model = VGG16(include_top=False)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bottleneck_features_train = \\\n",
    "        np.asarray([model.predict(np.expand_dims(train_tensor, axis=0))[0] for train_tensor in train_tensors], dtype=np.float32)\n",
    "\n",
    "bottleneck_features_valid = \\\n",
    "        np.asarray([model.predict(np.expand_dims(valid_tensor, axis=0))[0] for valid_tensor in valid_tensors], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save(open('bottleneck_features/driver_VGG16_train.npy', 'wb'), bottleneck_features_train)\n",
    "np.save(open('bottleneck_features/driver_VGG16_valid.npy', 'wb'), bottleneck_features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bottleneck_features_train = np.load('bottleneck_features/driver_VGG16_train.npy')\n",
    "# bottleneck_features_valid = np.load('bottleneck_features/driver_VGG16_valid.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "\n",
    "In our second CNN model using transfer learning of VGG16, we only add a global average pooling layer and a fully connected layer, where the latter contains one node for each driver behavior category and is equipped with a softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_12  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 33,778\n",
      "Trainable params: 33,630\n",
      "Non-trainable params: 148\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "VGG16_model = Sequential()\n",
    "\n",
    "VGG16_model.add(GlobalAveragePooling2D(input_shape=bottleneck_features_train.shape[1:]))\n",
    "\n",
    "VGG16_model.add(Dense(64))\n",
    "VGG16_model.add(BatchNormalization())\n",
    "VGG16_model.add(Activation('relu'))\n",
    "VGG16_model.add(Dropout(0.2))\n",
    "\n",
    "VGG16_model.add(Dense(10))\n",
    "VGG16_model.add(BatchNormalization())\n",
    "VGG16_model.add(Activation('softmax'))\n",
    "\n",
    "VGG16_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VGG16_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358 samples, validate on 90 samples\n",
      "Epoch 1/10\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 2.4347 - acc: 0.1750Epoch 00000: val_loss improved from inf to 2.46308, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "358/358 [==============================] - 2s - loss: 2.4082 - acc: 0.1760 - val_loss: 2.4631 - val_acc: 0.1111\n",
      "Epoch 2/10\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 1.8140 - acc: 0.4321Epoch 00001: val_loss improved from 2.46308 to 2.35780, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "358/358 [==============================] - 0s - loss: 1.8233 - acc: 0.4162 - val_loss: 2.3578 - val_acc: 0.1222\n",
      "Epoch 3/10\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 1.5463 - acc: 0.5143Epoch 00002: val_loss improved from 2.35780 to 2.30086, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "358/358 [==============================] - 0s - loss: 1.5620 - acc: 0.5084 - val_loss: 2.3009 - val_acc: 0.1444\n",
      "Epoch 4/10\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 1.3998 - acc: 0.6063Epoch 00003: val_loss improved from 2.30086 to 2.26159, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "358/358 [==============================] - 0s - loss: 1.4042 - acc: 0.6061 - val_loss: 2.2616 - val_acc: 0.2111\n",
      "Epoch 5/10\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 1.2439 - acc: 0.7267Epoch 00004: val_loss improved from 2.26159 to 2.23142, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "358/358 [==============================] - 0s - loss: 1.2558 - acc: 0.7123 - val_loss: 2.2314 - val_acc: 0.1778\n",
      "Epoch 6/10\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 1.1686 - acc: 0.7000Epoch 00005: val_loss did not improve\n",
      "358/358 [==============================] - 0s - loss: 1.1611 - acc: 0.7039 - val_loss: 2.2338 - val_acc: 0.0778\n",
      "Epoch 7/10\n",
      "240/358 [===================>..........] - ETA: 0s - loss: 1.0743 - acc: 0.7667Epoch 00006: val_loss improved from 2.23142 to 2.20109, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "358/358 [==============================] - 0s - loss: 1.0719 - acc: 0.7626 - val_loss: 2.2011 - val_acc: 0.1222\n",
      "Epoch 8/10\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 1.0200 - acc: 0.8033Epoch 00007: val_loss improved from 2.20109 to 2.15624, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "358/358 [==============================] - 0s - loss: 1.0166 - acc: 0.8017 - val_loss: 2.1562 - val_acc: 0.1556\n",
      "Epoch 9/10\n",
      "240/358 [===================>..........] - ETA: 0s - loss: 1.0037 - acc: 0.8167Epoch 00008: val_loss improved from 2.15624 to 2.14316, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "358/358 [==============================] - 0s - loss: 0.9857 - acc: 0.8156 - val_loss: 2.1432 - val_acc: 0.1000\n",
      "Epoch 10/10\n",
      "220/358 [=================>............] - ETA: 0s - loss: 0.8613 - acc: 0.8909Epoch 00009: val_loss improved from 2.14316 to 2.11208, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "358/358 [==============================] - 0s - loss: 0.8703 - acc: 0.8743 - val_loss: 2.1121 - val_acc: 0.1667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26662a069b0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.VGG16.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "VGG16_model.fit(bottleneck_features_train, train_targets, \n",
    "                validation_data=(bottleneck_features_valid, valid_targets),\n",
    "                epochs=20, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model with the Best Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VGG16_model.load_weights('saved_models/weights.best.VGG16.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "\n",
    "In the code cell below, we test our second CNN model (using transfer learning of VGG16) on the testing data set of driver images. The prediction probability results of all the test images are written into the csv file: **CNN_VGG16_test_probability.csv**, following the submission format defined by Kaggle.\n",
    "\n",
    "**The score (evaluation metrics: logarithmic loss function) of our second CNN model (using transfer learning of VGG16) is .**\n",
    "\n",
    "**The test result of our second CNN model (using transfer learning of VGG16) is ranked    out of 1440 in public leader board.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [02:39<00:00,  1.80s/it]\n"
     ]
    }
   ],
   "source": [
    "driver_behavior_predictions = []\n",
    "for test_file in tqdm(test_files):\n",
    "    test_tensor = path_to_tensor(test_file)\n",
    "    test_tensor = np.vstack(test_tensor).astype('float32')/255\n",
    "    test_bottleneck_feature = model.predict(np.expand_dims(test_tensor, axis=0))[0]\n",
    "    driver_behavior_predictions.append(VGG16_model.predict(np.expand_dims(test_bottleneck_feature, axis=0))[0])\n",
    "\n",
    "test_image_probability_csv = np.column_stack((np.asarray(test_image_filename_list), \\\n",
    "                                              np.asarray(driver_behavior_predictions, dtype=np.float32)))\n",
    "\n",
    "np.savetxt('submission/CNN_VGG16_test_probability.csv', test_image_probability_csv, delimiter=',', \\\n",
    "           comments='', newline='\\n', fmt='%s', header='img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9')\n",
    "\n",
    "# get index of predicted dog breed for each image in test set\n",
    "#VGG16_predictions = [np.argmax(VGG16_model.predict(np.expand_dims(feature, axis=0))) for feature in test_VGG16]\n",
    "\n",
    "# report test accuracy\n",
    "#test_accuracy = 100*np.sum(np.array(VGG16_predictions)==np.argmax(test_targets, axis=1))/len(VGG16_predictions)\n",
    "#print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from extract_bottleneck_features import *\n",
    "\n",
    "#def VGG16_predict_breed(img_path):\n",
    "#    # extract bottleneck features\n",
    "#    bottleneck_feature = extract_VGG16(path_to_tensor(img_path))\n",
    "#    # obtain predicted vector\n",
    "#    predicted_vector = VGG16_model.predict(bottleneck_feature)\n",
    "#    # return dog breed that is predicted by the model\n",
    "#    return dog_names[np.argmax(predicted_vector)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step4'></a>\n",
    "## Step 4: Create a CNN to classify driver images (using transfer learning)\n",
    "\n",
    "In this step, instead of VGG-16, we may try to use the other pre-trained models, which are\n",
    "like Xception or ResNet-50, for different model choices of transfer learning. We can compare\n",
    "these CNN models with the above one (VGG-16) and check the differences between their prediction scores.\n",
    "\n",
    "## Xception \n",
    "### Obtain Bottleneck Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_9 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)            (None, None, None, 32 864         input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormalizat (None, None, None, 32 128         block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)    (None, None, None, 32 0           block1_conv1_bn[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)            (None, None, None, 64 18432       block1_conv1_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormalizat (None, None, None, 64 256         block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)    (None, None, None, 64 0           block1_conv2_bn[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2D (None, None, None, 12 8768        block1_conv2_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormali (None, None, None, 12 512         block2_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation) (None, None, None, 12 0           block2_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2D (None, None, None, 12 17536       block2_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormali (None, None, None, 12 512         block2_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)               (None, None, None, 12 8192        block1_conv2_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, None, None, 12 0           block2_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNor (None, None, None, 12 512         conv2d_35[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_65 (Add)                     (None, None, None, 12 0           block2_pool[0][0]                \n",
      "                                                                   batch_normalization_46[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation) (None, None, None, 12 0           add_65[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2D (None, None, None, 25 33920       block3_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormali (None, None, None, 25 1024        block3_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation) (None, None, None, 25 0           block3_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2D (None, None, None, 25 67840       block3_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormali (None, None, None, 25 1024        block3_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)               (None, None, None, 25 32768       add_65[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, None, None, 25 0           block3_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNor (None, None, None, 25 1024        conv2d_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_66 (Add)                     (None, None, None, 25 0           block3_pool[0][0]                \n",
      "                                                                   batch_normalization_47[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation) (None, None, None, 25 0           add_66[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2D (None, None, None, 72 188672      block4_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block4_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation) (None, None, None, 72 0           block4_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block4_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block4_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)               (None, None, None, 72 186368      add_66[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, None, None, 72 0           block4_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNor (None, None, None, 72 2912        conv2d_37[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_67 (Add)                     (None, None, None, 72 0           block4_pool[0][0]                \n",
      "                                                                   batch_normalization_48[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation) (None, None, None, 72 0           add_67[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2D (None, None, None, 72 536536      block5_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block5_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation) (None, None, None, 72 0           block5_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block5_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block5_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation) (None, None, None, 72 0           block5_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2D (None, None, None, 72 536536      block5_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormali (None, None, None, 72 2912        block5_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_68 (Add)                     (None, None, None, 72 0           block5_sepconv3_bn[0][0]         \n",
      "                                                                   add_67[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation) (None, None, None, 72 0           add_68[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2D (None, None, None, 72 536536      block6_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block6_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation) (None, None, None, 72 0           block6_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block6_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block6_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation) (None, None, None, 72 0           block6_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2D (None, None, None, 72 536536      block6_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormali (None, None, None, 72 2912        block6_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_69 (Add)                     (None, None, None, 72 0           block6_sepconv3_bn[0][0]         \n",
      "                                                                   add_68[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation) (None, None, None, 72 0           add_69[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2D (None, None, None, 72 536536      block7_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block7_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation) (None, None, None, 72 0           block7_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block7_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block7_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation) (None, None, None, 72 0           block7_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2D (None, None, None, 72 536536      block7_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormali (None, None, None, 72 2912        block7_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_70 (Add)                     (None, None, None, 72 0           block7_sepconv3_bn[0][0]         \n",
      "                                                                   add_69[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation) (None, None, None, 72 0           add_70[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2D (None, None, None, 72 536536      block8_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block8_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation) (None, None, None, 72 0           block8_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block8_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block8_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation) (None, None, None, 72 0           block8_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2D (None, None, None, 72 536536      block8_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormali (None, None, None, 72 2912        block8_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_71 (Add)                     (None, None, None, 72 0           block8_sepconv3_bn[0][0]         \n",
      "                                                                   add_70[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation) (None, None, None, 72 0           add_71[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2D (None, None, None, 72 536536      block9_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block9_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation) (None, None, None, 72 0           block9_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block9_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block9_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation) (None, None, None, 72 0           block9_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2D (None, None, None, 72 536536      block9_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormali (None, None, None, 72 2912        block9_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_72 (Add)                     (None, None, None, 72 0           block9_sepconv3_bn[0][0]         \n",
      "                                                                   add_71[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activation (None, None, None, 72 0           add_72[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv2 (None, None, None, 72 536536      block10_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNormal (None, None, None, 72 2912        block10_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activation (None, None, None, 72 0           block10_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv2 (None, None, None, 72 536536      block10_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNormal (None, None, None, 72 2912        block10_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activation (None, None, None, 72 0           block10_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv2 (None, None, None, 72 536536      block10_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNormal (None, None, None, 72 2912        block10_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_73 (Add)                     (None, None, None, 72 0           block10_sepconv3_bn[0][0]        \n",
      "                                                                   add_72[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activation (None, None, None, 72 0           add_73[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv2 (None, None, None, 72 536536      block11_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNormal (None, None, None, 72 2912        block11_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activation (None, None, None, 72 0           block11_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv2 (None, None, None, 72 536536      block11_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNormal (None, None, None, 72 2912        block11_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activation (None, None, None, 72 0           block11_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv2 (None, None, None, 72 536536      block11_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNormal (None, None, None, 72 2912        block11_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_74 (Add)                     (None, None, None, 72 0           block11_sepconv3_bn[0][0]        \n",
      "                                                                   add_73[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activation (None, None, None, 72 0           add_74[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv2 (None, None, None, 72 536536      block12_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNormal (None, None, None, 72 2912        block12_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activation (None, None, None, 72 0           block12_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv2 (None, None, None, 72 536536      block12_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNormal (None, None, None, 72 2912        block12_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activation (None, None, None, 72 0           block12_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv2 (None, None, None, 72 536536      block12_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNormal (None, None, None, 72 2912        block12_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_75 (Add)                     (None, None, None, 72 0           block12_sepconv3_bn[0][0]        \n",
      "                                                                   add_74[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activation (None, None, None, 72 0           add_75[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv2 (None, None, None, 72 536536      block13_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNormal (None, None, None, 72 2912        block13_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activation (None, None, None, 72 0           block13_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv2 (None, None, None, 10 752024      block13_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNormal (None, None, None, 10 4096        block13_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)               (None, None, None, 10 745472      add_75[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)      (None, None, None, 10 0           block13_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNor (None, None, None, 10 4096        conv2d_38[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_76 (Add)                     (None, None, None, 10 0           block13_pool[0][0]               \n",
      "                                                                   batch_normalization_49[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv2 (None, None, None, 15 1582080     add_76[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNormal (None, None, None, 15 6144        block14_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activation (None, None, None, 15 0           block14_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv2 (None, None, None, 20 3159552     block14_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNormal (None, None, None, 20 8192        block14_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activation (None, None, None, 20 0           block14_sepconv2_bn[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 20,806,952\n",
      "Non-trainable params: 54,528\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.xception import Xception\n",
    "\n",
    "# https://keras.io/applications/#xception\n",
    "# NOT include the fully-connected layer at the top of the network.\n",
    "model = Xception(include_top=False)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bottleneck_features_train = \\\n",
    "        np.asarray([model.predict(np.expand_dims(train_tensor, axis=0))[0] for train_tensor in train_tensors], dtype=np.float32)\n",
    "\n",
    "bottleneck_features_valid = \\\n",
    "        np.asarray([model.predict(np.expand_dims(valid_tensor, axis=0))[0] for valid_tensor in valid_tensors], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(open('bottleneck_features/driver_Xception_train.npy', 'wb'), bottleneck_features_train)\n",
    "np.save(open('bottleneck_features/driver_Xception_valid.npy', 'wb'), bottleneck_features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bottleneck_features_train = np.load('bottleneck_features/driver_Xception_train.npy')\n",
    "# bottleneck_features_valid = np.load('bottleneck_features/driver_Xception_valid.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_16  (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 132,082\n",
      "Trainable params: 131,934\n",
      "Non-trainable params: 148\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Xception_model = Sequential()\n",
    "\n",
    "Xception_model.add(GlobalAveragePooling2D(input_shape=bottleneck_features_train.shape[1:]))\n",
    "\n",
    "Xception_model.add(Dense(64))\n",
    "Xception_model.add(BatchNormalization())\n",
    "Xception_model.add(Activation('relu'))\n",
    "Xception_model.add(Dropout(0.2))\n",
    "\n",
    "Xception_model.add(Dense(10))\n",
    "Xception_model.add(BatchNormalization())\n",
    "Xception_model.add(Activation('softmax'))\n",
    "\n",
    "Xception_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xception_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358 samples, validate on 90 samples\n",
      "Epoch 1/10\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 2.0715 - acc: 0.3176Epoch 00000: val_loss improved from inf to 2.09747, saving model to saved_models/weights.best.Xception.hdf5\n",
      "358/358 [==============================] - 4s - loss: 2.0576 - acc: 0.3240 - val_loss: 2.0975 - val_acc: 0.2556\n",
      "Epoch 2/10\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 1.3261 - acc: 0.6265Epoch 00001: val_loss improved from 2.09747 to 1.92620, saving model to saved_models/weights.best.Xception.hdf5\n",
      "358/358 [==============================] - 0s - loss: 1.3229 - acc: 0.6257 - val_loss: 1.9262 - val_acc: 0.3889\n",
      "Epoch 3/10\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 1.0522 - acc: 0.7906Epoch 00002: val_loss improved from 1.92620 to 1.87524, saving model to saved_models/weights.best.Xception.hdf5\n",
      "358/358 [==============================] - 0s - loss: 1.0479 - acc: 0.7905 - val_loss: 1.8752 - val_acc: 0.4000\n",
      "Epoch 4/10\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.9161 - acc: 0.8235Epoch 00003: val_loss improved from 1.87524 to 1.72741, saving model to saved_models/weights.best.Xception.hdf5\n",
      "358/358 [==============================] - 0s - loss: 0.9219 - acc: 0.8156 - val_loss: 1.7274 - val_acc: 0.5111\n",
      "Epoch 5/10\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.8487 - acc: 0.8625Epoch 00004: val_loss improved from 1.72741 to 1.63038, saving model to saved_models/weights.best.Xception.hdf5\n",
      "358/358 [==============================] - 0s - loss: 0.8537 - acc: 0.8603 - val_loss: 1.6304 - val_acc: 0.5556\n",
      "Epoch 6/10\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.7720 - acc: 0.9187Epoch 00005: val_loss improved from 1.63038 to 1.47848, saving model to saved_models/weights.best.Xception.hdf5\n",
      "358/358 [==============================] - 0s - loss: 0.7726 - acc: 0.9162 - val_loss: 1.4785 - val_acc: 0.5778\n",
      "Epoch 7/10\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.7863 - acc: 0.8656Epoch 00006: val_loss improved from 1.47848 to 1.41932, saving model to saved_models/weights.best.Xception.hdf5\n",
      "358/358 [==============================] - 0s - loss: 0.7892 - acc: 0.8659 - val_loss: 1.4193 - val_acc: 0.7000\n",
      "Epoch 8/10\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.7402 - acc: 0.9000Epoch 00007: val_loss did not improve\n",
      "358/358 [==============================] - 0s - loss: 0.7344 - acc: 0.9050 - val_loss: 1.4202 - val_acc: 0.6889\n",
      "Epoch 9/10\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.6815 - acc: 0.9147Epoch 00008: val_loss improved from 1.41932 to 1.32981, saving model to saved_models/weights.best.Xception.hdf5\n",
      "358/358 [==============================] - 0s - loss: 0.6838 - acc: 0.9134 - val_loss: 1.3298 - val_acc: 0.6889\n",
      "Epoch 10/10\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.6194 - acc: 0.9500Epoch 00009: val_loss improved from 1.32981 to 1.25392, saving model to saved_models/weights.best.Xception.hdf5\n",
      "358/358 [==============================] - 0s - loss: 0.6185 - acc: 0.9497 - val_loss: 1.2539 - val_acc: 0.6778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2665f4b8e48>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.Xception.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "Xception_model.fit(bottleneck_features_train, train_targets, \n",
    "                   validation_data=(bottleneck_features_valid, valid_targets),\n",
    "                   epochs=20, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model with the Best Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xception_model.load_weights('saved_models/weights.best.Xception.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "\n",
    "In the code cell below, we test our CNN model using transfer learning of Xception on the testing data set of driver images. The prediction probability results of all the test images are written into the csv file: **CNN_Xception_test_probability.csv**, following the submission format defined by Kaggle.\n",
    "\n",
    "**The score (evaluation metrics: logarithmic loss function) of our CNN model using transfer learning of Xception is .**\n",
    "\n",
    "**The test result of our CNN model using transfer learning of Xception is ranked    out of 1440 in public leader board.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [02:03<00:00,  1.31s/it]\n"
     ]
    }
   ],
   "source": [
    "driver_behavior_predictions = []\n",
    "for test_file in tqdm(test_files):\n",
    "    test_tensor = path_to_tensor(test_file)\n",
    "    test_tensor = np.vstack(test_tensor).astype('float32')/255\n",
    "    test_bottleneck_feature = model.predict(np.expand_dims(test_tensor, axis=0))[0]\n",
    "    driver_behavior_predictions.append(Xception_model.predict(np.expand_dims(test_bottleneck_feature, axis=0))[0])\n",
    "\n",
    "test_image_probability_csv = np.column_stack((np.asarray(test_image_filename_list), \\\n",
    "                                              np.asarray(driver_behavior_predictions, dtype=np.float32)))\n",
    "\n",
    "np.savetxt('submission/CNN_Xception_test_probability.csv', test_image_probability_csv, delimiter=',', \\\n",
    "           comments='', newline='\\n', fmt='%s', header='img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9')\n",
    "\n",
    "# get index of predicted dog breed for each image in test set\n",
    "#VGG16_predictions = [np.argmax(VGG16_model.predict(np.expand_dims(feature, axis=0))) for feature in test_VGG16]\n",
    "\n",
    "# report test accuracy\n",
    "#test_accuracy = 100*np.sum(np.array(VGG16_predictions)==np.argmax(test_targets, axis=1))/len(VGG16_predictions)\n",
    "#print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50\n",
    "### Obtain Bottleneck Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_10 (InputLayer)            (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                   (None, None, None, 64 9472        input_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)    (None, None, None, 64 256         conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_64 (Activation)       (None, None, None, 64 0           bn_conv1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D)  (None, None, None, 64 0           activation_64[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)          (None, None, None, 64 4160        max_pooling2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizatio (None, None, None, 64 256         res2a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_65 (Activation)       (None, None, None, 64 0           bn2a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)          (None, None, None, 64 36928       activation_65[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizatio (None, None, None, 64 256         res2a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_66 (Activation)       (None, None, None, 64 0           bn2a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)          (None, None, None, 25 16640       activation_66[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)           (None, None, None, 25 16640       max_pooling2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizatio (None, None, None, 25 1024        res2a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalization (None, None, None, 25 1024        res2a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_77 (Add)                     (None, None, None, 25 0           bn2a_branch2c[0][0]              \n",
      "                                                                   bn2a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_67 (Activation)       (None, None, None, 25 0           add_77[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)          (None, None, None, 64 16448       activation_67[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizatio (None, None, None, 64 256         res2b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_68 (Activation)       (None, None, None, 64 0           bn2b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)          (None, None, None, 64 36928       activation_68[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizatio (None, None, None, 64 256         res2b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_69 (Activation)       (None, None, None, 64 0           bn2b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)          (None, None, None, 25 16640       activation_69[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizatio (None, None, None, 25 1024        res2b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_78 (Add)                     (None, None, None, 25 0           bn2b_branch2c[0][0]              \n",
      "                                                                   activation_67[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_70 (Activation)       (None, None, None, 25 0           add_78[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)          (None, None, None, 64 16448       activation_70[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizatio (None, None, None, 64 256         res2c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_71 (Activation)       (None, None, None, 64 0           bn2c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)          (None, None, None, 64 36928       activation_71[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizatio (None, None, None, 64 256         res2c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_72 (Activation)       (None, None, None, 64 0           bn2c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)          (None, None, None, 25 16640       activation_72[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizatio (None, None, None, 25 1024        res2c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_79 (Add)                     (None, None, None, 25 0           bn2c_branch2c[0][0]              \n",
      "                                                                   activation_70[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_73 (Activation)       (None, None, None, 25 0           add_79[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)          (None, None, None, 12 32896       activation_73[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizatio (None, None, None, 12 512         res3a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_74 (Activation)       (None, None, None, 12 0           bn3a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)          (None, None, None, 12 147584      activation_74[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizatio (None, None, None, 12 512         res3a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_75 (Activation)       (None, None, None, 12 0           bn3a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)          (None, None, None, 51 66048       activation_75[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)           (None, None, None, 51 131584      activation_73[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizatio (None, None, None, 51 2048        res3a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalization (None, None, None, 51 2048        res3a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_80 (Add)                     (None, None, None, 51 0           bn3a_branch2c[0][0]              \n",
      "                                                                   bn3a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_76 (Activation)       (None, None, None, 51 0           add_80[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)          (None, None, None, 12 65664       activation_76[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizatio (None, None, None, 12 512         res3b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_77 (Activation)       (None, None, None, 12 0           bn3b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)          (None, None, None, 12 147584      activation_77[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizatio (None, None, None, 12 512         res3b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_78 (Activation)       (None, None, None, 12 0           bn3b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)          (None, None, None, 51 66048       activation_78[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizatio (None, None, None, 51 2048        res3b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_81 (Add)                     (None, None, None, 51 0           bn3b_branch2c[0][0]              \n",
      "                                                                   activation_76[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_79 (Activation)       (None, None, None, 51 0           add_81[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)          (None, None, None, 12 65664       activation_79[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizatio (None, None, None, 12 512         res3c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_80 (Activation)       (None, None, None, 12 0           bn3c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)          (None, None, None, 12 147584      activation_80[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizatio (None, None, None, 12 512         res3c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_81 (Activation)       (None, None, None, 12 0           bn3c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)          (None, None, None, 51 66048       activation_81[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizatio (None, None, None, 51 2048        res3c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_82 (Add)                     (None, None, None, 51 0           bn3c_branch2c[0][0]              \n",
      "                                                                   activation_79[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_82 (Activation)       (None, None, None, 51 0           add_82[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)          (None, None, None, 12 65664       activation_82[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizatio (None, None, None, 12 512         res3d_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_83 (Activation)       (None, None, None, 12 0           bn3d_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)          (None, None, None, 12 147584      activation_83[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizatio (None, None, None, 12 512         res3d_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_84 (Activation)       (None, None, None, 12 0           bn3d_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)          (None, None, None, 51 66048       activation_84[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizatio (None, None, None, 51 2048        res3d_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_83 (Add)                     (None, None, None, 51 0           bn3d_branch2c[0][0]              \n",
      "                                                                   activation_82[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_85 (Activation)       (None, None, None, 51 0           add_83[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)          (None, None, None, 25 131328      activation_85[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizatio (None, None, None, 25 1024        res4a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_86 (Activation)       (None, None, None, 25 0           bn4a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)          (None, None, None, 25 590080      activation_86[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizatio (None, None, None, 25 1024        res4a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_87 (Activation)       (None, None, None, 25 0           bn4a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)          (None, None, None, 10 263168      activation_87[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)           (None, None, None, 10 525312      activation_85[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizatio (None, None, None, 10 4096        res4a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalization (None, None, None, 10 4096        res4a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_84 (Add)                     (None, None, None, 10 0           bn4a_branch2c[0][0]              \n",
      "                                                                   bn4a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_88 (Activation)       (None, None, None, 10 0           add_84[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)          (None, None, None, 25 262400      activation_88[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizatio (None, None, None, 25 1024        res4b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_89 (Activation)       (None, None, None, 25 0           bn4b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)          (None, None, None, 25 590080      activation_89[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizatio (None, None, None, 25 1024        res4b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_90 (Activation)       (None, None, None, 25 0           bn4b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)          (None, None, None, 10 263168      activation_90[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizatio (None, None, None, 10 4096        res4b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_85 (Add)                     (None, None, None, 10 0           bn4b_branch2c[0][0]              \n",
      "                                                                   activation_88[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_91 (Activation)       (None, None, None, 10 0           add_85[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)          (None, None, None, 25 262400      activation_91[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizatio (None, None, None, 25 1024        res4c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_92 (Activation)       (None, None, None, 25 0           bn4c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)          (None, None, None, 25 590080      activation_92[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizatio (None, None, None, 25 1024        res4c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_93 (Activation)       (None, None, None, 25 0           bn4c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)          (None, None, None, 10 263168      activation_93[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizatio (None, None, None, 10 4096        res4c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_86 (Add)                     (None, None, None, 10 0           bn4c_branch2c[0][0]              \n",
      "                                                                   activation_91[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_94 (Activation)       (None, None, None, 10 0           add_86[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)          (None, None, None, 25 262400      activation_94[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizatio (None, None, None, 25 1024        res4d_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_95 (Activation)       (None, None, None, 25 0           bn4d_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)          (None, None, None, 25 590080      activation_95[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizatio (None, None, None, 25 1024        res4d_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_96 (Activation)       (None, None, None, 25 0           bn4d_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)          (None, None, None, 10 263168      activation_96[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizatio (None, None, None, 10 4096        res4d_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_87 (Add)                     (None, None, None, 10 0           bn4d_branch2c[0][0]              \n",
      "                                                                   activation_94[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_97 (Activation)       (None, None, None, 10 0           add_87[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)          (None, None, None, 25 262400      activation_97[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizatio (None, None, None, 25 1024        res4e_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_98 (Activation)       (None, None, None, 25 0           bn4e_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)          (None, None, None, 25 590080      activation_98[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizatio (None, None, None, 25 1024        res4e_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_99 (Activation)       (None, None, None, 25 0           bn4e_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)          (None, None, None, 10 263168      activation_99[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizatio (None, None, None, 10 4096        res4e_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_88 (Add)                     (None, None, None, 10 0           bn4e_branch2c[0][0]              \n",
      "                                                                   activation_97[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_100 (Activation)      (None, None, None, 10 0           add_88[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)          (None, None, None, 25 262400      activation_100[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizatio (None, None, None, 25 1024        res4f_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_101 (Activation)      (None, None, None, 25 0           bn4f_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)          (None, None, None, 25 590080      activation_101[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizatio (None, None, None, 25 1024        res4f_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_102 (Activation)      (None, None, None, 25 0           bn4f_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)          (None, None, None, 10 263168      activation_102[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizatio (None, None, None, 10 4096        res4f_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_89 (Add)                     (None, None, None, 10 0           bn4f_branch2c[0][0]              \n",
      "                                                                   activation_100[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_103 (Activation)      (None, None, None, 10 0           add_89[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)          (None, None, None, 51 524800      activation_103[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizatio (None, None, None, 51 2048        res5a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_104 (Activation)      (None, None, None, 51 0           bn5a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)          (None, None, None, 51 2359808     activation_104[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizatio (None, None, None, 51 2048        res5a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_105 (Activation)      (None, None, None, 51 0           bn5a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)          (None, None, None, 20 1050624     activation_105[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)           (None, None, None, 20 2099200     activation_103[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizatio (None, None, None, 20 8192        res5a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalization (None, None, None, 20 8192        res5a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_90 (Add)                     (None, None, None, 20 0           bn5a_branch2c[0][0]              \n",
      "                                                                   bn5a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_106 (Activation)      (None, None, None, 20 0           add_90[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)          (None, None, None, 51 1049088     activation_106[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizatio (None, None, None, 51 2048        res5b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_107 (Activation)      (None, None, None, 51 0           bn5b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)          (None, None, None, 51 2359808     activation_107[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizatio (None, None, None, 51 2048        res5b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_108 (Activation)      (None, None, None, 51 0           bn5b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)          (None, None, None, 20 1050624     activation_108[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizatio (None, None, None, 20 8192        res5b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_91 (Add)                     (None, None, None, 20 0           bn5b_branch2c[0][0]              \n",
      "                                                                   activation_106[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_109 (Activation)      (None, None, None, 20 0           add_91[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)          (None, None, None, 51 1049088     activation_109[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizatio (None, None, None, 51 2048        res5c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_110 (Activation)      (None, None, None, 51 0           bn5c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)          (None, None, None, 51 2359808     activation_110[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizatio (None, None, None, 51 2048        res5c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_111 (Activation)      (None, None, None, 51 0           bn5c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)          (None, None, None, 20 1050624     activation_111[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizatio (None, None, None, 20 8192        res5c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_92 (Add)                     (None, None, None, 20 0           bn5c_branch2c[0][0]              \n",
      "                                                                   activation_109[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_112 (Activation)      (None, None, None, 20 0           add_92[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)      (None, None, None, 20 0           activation_112[0][0]             \n",
      "====================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "# https://keras.io/applications/#resnet50\n",
    "# NOT include the fully-connected layer at the top of the network.\n",
    "model = ResNet50(include_top=False)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bottleneck_features_train = \\\n",
    "        np.asarray([model.predict(np.expand_dims(train_tensor, axis=0))[0] for train_tensor in train_tensors], dtype=np.float32)\n",
    "\n",
    "bottleneck_features_valid = \\\n",
    "        np.asarray([model.predict(np.expand_dims(valid_tensor, axis=0))[0] for valid_tensor in valid_tensors], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(open('bottleneck_features/driver_ResNet50_train.npy', 'wb'), bottleneck_features_train)\n",
    "np.save(open('bottleneck_features/driver_ResNet50_valid.npy', 'wb'), bottleneck_features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bottleneck_features_train = np.load('bottleneck_features/driver_ResNet50_train.npy')\n",
    "# bottleneck_features_valid = np.load('bottleneck_features/driver_ResNet50_valid.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_18  (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 132,082\n",
      "Trainable params: 131,934\n",
      "Non-trainable params: 148\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ResNet50_model = Sequential()\n",
    "\n",
    "ResNet50_model.add(GlobalAveragePooling2D(input_shape=bottleneck_features_train.shape[1:]))\n",
    "\n",
    "ResNet50_model.add(Dense(64))\n",
    "ResNet50_model.add(BatchNormalization())\n",
    "ResNet50_model.add(Activation('relu'))\n",
    "ResNet50_model.add(Dropout(0.2))\n",
    "\n",
    "ResNet50_model.add(Dense(10))\n",
    "ResNet50_model.add(BatchNormalization())\n",
    "ResNet50_model.add(Activation('softmax'))\n",
    "\n",
    "ResNet50_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ResNet50_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358 samples, validate on 90 samples\n",
      "Epoch 1/10\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 2.4843 - acc: 0.1567Epoch 00000: val_loss improved from inf to 2.57054, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "358/358 [==============================] - 3s - loss: 2.4452 - acc: 0.1676 - val_loss: 2.5705 - val_acc: 0.0778\n",
      "Epoch 2/10\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 1.9533 - acc: 0.3353Epoch 00001: val_loss improved from 2.57054 to 2.53871, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "358/358 [==============================] - 0s - loss: 1.9426 - acc: 0.3436 - val_loss: 2.5387 - val_acc: 0.0778\n",
      "Epoch 3/10\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 1.6920 - acc: 0.4313Epoch 00002: val_loss improved from 2.53871 to 2.51430, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "358/358 [==============================] - 0s - loss: 1.7165 - acc: 0.4190 - val_loss: 2.5143 - val_acc: 0.1000\n",
      "Epoch 4/10\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 1.5587 - acc: 0.5406Epoch 00003: val_loss did not improve\n",
      "358/358 [==============================] - 0s - loss: 1.5570 - acc: 0.5391 - val_loss: 2.5904 - val_acc: 0.0889\n",
      "Epoch 5/10\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 1.4123 - acc: 0.5667Epoch 00004: val_loss did not improve\n",
      "358/358 [==============================] - 0s - loss: 1.4127 - acc: 0.5615 - val_loss: 2.6037 - val_acc: 0.1222\n",
      "Epoch 6/10\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 1.3744 - acc: 0.5900Epoch 00005: val_loss did not improve\n",
      "358/358 [==============================] - 0s - loss: 1.3684 - acc: 0.6034 - val_loss: 2.5305 - val_acc: 0.0778\n",
      "Epoch 7/10\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 1.2480 - acc: 0.6643Epoch 00006: val_loss did not improve\n",
      "358/358 [==============================] - 0s - loss: 1.2487 - acc: 0.6564 - val_loss: 2.5785 - val_acc: 0.1222\n",
      "Epoch 8/10\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 1.2075 - acc: 0.6750Epoch 00007: val_loss did not improve\n",
      "358/358 [==============================] - 0s - loss: 1.2014 - acc: 0.6816 - val_loss: 2.5437 - val_acc: 0.1556\n",
      "Epoch 9/10\n",
      "240/358 [===================>..........] - ETA: 0s - loss: 1.1774 - acc: 0.7042Epoch 00008: val_loss improved from 2.51430 to 2.40959, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "358/358 [==============================] - 0s - loss: 1.1768 - acc: 0.7011 - val_loss: 2.4096 - val_acc: 0.1000\n",
      "Epoch 10/10\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 1.1338 - acc: 0.7062Epoch 00009: val_loss did not improve\n",
      "358/358 [==============================] - 0s - loss: 1.1273 - acc: 0.7067 - val_loss: 2.6678 - val_acc: 0.0556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26664445630>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.ResNet50.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "ResNet50_model.fit(bottleneck_features_train, train_targets, \n",
    "                   validation_data=(bottleneck_features_valid, valid_targets),\n",
    "                   epochs=20, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model with the Best Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ResNet50_model.load_weights('saved_models/weights.best.ResNet50.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "\n",
    "In the code cell below, we test our CNN model using transfer learning of ResNet50 on the testing data set of driver images. The prediction probability results of all the test images are written into the csv file: **CNN_ResNet50_test_probability.csv**, following the submission format defined by Kaggle.\n",
    "\n",
    "**The score (evaluation metrics: logarithmic loss function) of our CNN model using transfer learning of ResNet50 is .**\n",
    "\n",
    "**The test result of our CNN model using transfer learning of ResNet50 is ranked    out of 1440 in public leader board.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [01:49<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "driver_behavior_predictions = []\n",
    "for test_file in tqdm(test_files):\n",
    "    test_tensor = path_to_tensor(test_file)\n",
    "    test_tensor = np.vstack(test_tensor).astype('float32')/255\n",
    "    test_bottleneck_feature = model.predict(np.expand_dims(test_tensor, axis=0))[0]\n",
    "    driver_behavior_predictions.append(ResNet50_model.predict(np.expand_dims(test_bottleneck_feature, axis=0))[0])\n",
    "\n",
    "test_image_probability_csv = np.column_stack((np.asarray(test_image_filename_list), \\\n",
    "                                              np.asarray(driver_behavior_predictions, dtype=np.float32)))\n",
    "\n",
    "np.savetxt('submission/CNN_ResNet50_test_probability.csv', test_image_probability_csv, delimiter=',', \\\n",
    "           comments='', newline='\\n', fmt='%s', header='img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9')\n",
    "\n",
    "# get index of predicted dog breed for each image in test set\n",
    "#VGG16_predictions = [np.argmax(VGG16_model.predict(np.expand_dims(feature, axis=0))) for feature in test_VGG16]\n",
    "\n",
    "# report test accuracy\n",
    "#test_accuracy = 100*np.sum(np.array(VGG16_predictions)==np.argmax(test_targets, axis=1))/len(VGG16_predictions)\n",
    "#print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def Resnet50_predict_breed(img_path):\n",
    "#    # extract bottleneck features\n",
    "#    # VGG19, Resnet50, InceptionV3, or Xception\n",
    "#    bottleneck_feature = extract_Resnet50(path_to_tensor(img_path))\n",
    "#    # obtain predicted vector\n",
    "#    predicted_vector = Resnet50_model.predict(bottleneck_feature)\n",
    "#    # return dog breed that is predicted by the model\n",
    "#    return dog_names[np.argmax(predicted_vector)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step5'></a>\n",
    "## Step 5: Algorithm test result\n",
    "\n",
    "We choose the best result (the lowest score of the evaluation metric of log-loss error function) among the CNN models we\n",
    "construct above to be the final output of our proposed algorithm.\n",
    "\n",
    "**The CNN model we construct above with the lowest score of log-loss function is:  , and this CNN model has the score of  .**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
